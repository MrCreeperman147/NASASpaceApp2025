"""
API Sentinel-2 et Donn√©es de Mar√©e - Version S√©curis√©e
Credentials charg√©s depuis credentials.json
"""
import requests
from datetime import datetime, timedelta
import json
import csv
from pathlib import Path
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload
import os
import pickle
import io

# ============================================================================
# CHARGEMENT S√âCURIS√â DES CREDENTIALS
# ============================================================================

def load_credentials(credentials_file="credentials.json"):
    """
    Charge les credentials depuis le fichier JSON
    
    Args:
        credentials_file: Chemin vers le fichier credentials.json
    
    Returns:
        Dict avec les credentials
    """
    try:
        with open(credentials_file, 'r') as f:
            creds = json.load(f)
        
        # V√©rifier que les credentials Copernicus sont pr√©sents
        if 'copernicus' not in creds:
            raise KeyError("Section 'copernicus' manquante dans credentials.json")
        
        if 'username' not in creds['copernicus'] or 'password' not in creds['copernicus']:
            raise KeyError("username ou password manquant dans credentials.copernicus")
        
        return creds
    
    except FileNotFoundError:
        print(f"‚ùå ERREUR: Fichier '{credentials_file}' introuvable!")
        print("\nüí° Cr√©ez un fichier credentials.json avec ce format:")
        print("""
{
  "copernicus": {
    "username": "votre_email@example.com",
    "password": "votre_mot_de_passe"
  },
  "installed": {
    "client_id": "...",
    "project_id": "...",
    "auth_uri": "https://accounts.google.com/o/oauth2/auth",
    "token_uri": "https://oauth2.googleapis.com/token",
    "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
    "client_secret": "...",
    "redirect_uris": ["http://localhost"]
  }
}
        """)
        raise
    
    except json.JSONDecodeError as e:
        print(f"‚ùå ERREUR: Le fichier credentials.json n'est pas un JSON valide: {e}")
        raise
    
    except KeyError as e:
        print(f"‚ùå ERREUR: Credentials invalides - {e}")
        raise


# Scopes n√©cessaires pour Google Drive
SCOPES = ['https://www.googleapis.com/auth/drive.file']

# ============================================================================
# PARTIE 1A: API IWLS - DONN√âES DE MAR√âE (P√™ches et Oc√©ans Canada)
# ============================================================================

def get_tide_data_from_api(station_id="5cebf1e33d0f4a073c4bc285", start_date=None, end_date=None):
    """
    R√©cup√©rer les donn√©es de mar√©e depuis l'API IWLS
    
    Args:
        station_id: Code de la station (5cebf1e33d0f4a073c4bc285 = Cap-aux-Meules)
        start_date: Date de d√©but (datetime ou string YYYY-MM-DD)
        end_date: Date de fin (datetime ou string YYYY-MM-DD)
    
    Returns:
        Liste des pr√©dictions de mar√©e au format standard
    """
    from datetime import timezone
    
    # NOUVELLE API IWLS (2024+)
    base_url = "https://api.iwls-sine.azure.cloud-nuage.dfo-mpo.gc.ca/api/v1"
    
    # Convertir les dates si n√©cessaire
    if isinstance(start_date, str):
        start_date = datetime.strptime(start_date, '%Y-%m-%d')
    if isinstance(end_date, str):
        end_date = datetime.strptime(end_date, '%Y-%m-%d')
    
    # Si pas de dates, utiliser aujourd'hui + 7 jours
    if not start_date:
        start_date = datetime.now()
    if not end_date:
        end_date = start_date + timedelta(days=7)
    
    print(f"\nüåä R√©cup√©ration des donn√©es de mar√©e depuis l'API IWLS...")
    print(f"   Station: Cap-aux-Meules ({station_id})")
    print(f"   P√©riode: {start_date.strftime('%Y-%m-%d')} ‚Üí {end_date.strftime('%Y-%m-%d')}")
    
    # Liste des codes de s√©ries temporelles √† essayer
    time_series_codes = [
        ('wlp', 'Pr√©dictions'),
        ('wlp-hilo', 'Hautes/Basses eaux pr√©dites'),
        ('wlo', 'Observations'),
        ('wlf', 'Pr√©visions'),
    ]
    
    for code, description in time_series_codes:
        # Endpoint pour les donn√©es de mar√©e
        url = f"{base_url}/stations/{station_id}/data"
        
        # Formater les dates selon le format ISO 8601
        from_date = start_date.isoformat() + 'Z'
        to_date = end_date.isoformat() + 'Z'
        
        params = {
            'time-series-code': code,
            'from': from_date,
            'to': to_date
        }
        
        try:
            print(f"   Essai avec '{code}' ({description})...", end='')
            response = requests.get(url, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                
                if isinstance(data, list) and len(data) > 0:
                    print(f" ‚úì {len(data)} enregistrements r√©cup√©r√©s")
                    
                    # Convertir au format standard
                    tide_data = []
                    for record in data:
                        dt = datetime.fromisoformat(record['eventDate'].replace('Z', '+00:00'))
                        if dt.tzinfo is None:
                            dt = dt.replace(tzinfo=timezone.utc)
                        
                        tide_data.append({
                            'datetime': dt,
                            'tide_level_m': record.get('value')
                        })
                    
                    return tide_data
                else:
                    print(f" ‚ö†Ô∏è  Aucune donn√©e")
            else:
                print(f" ‚úó Erreur {response.status_code}")
                
        except Exception as e:
            print(f" ‚úó Erreur: {e}")
            continue
    
    print(f"\n   ‚úó Aucune donn√©e de mar√©e disponible pour cette station/p√©riode")
    return []


# ============================================================================
# PARTIE 1B: CHARGEMENT DES DONN√âES DE MAR√âE DEPUIS CSV
# ============================================================================

def load_tide_data_from_csv(csv_file_path, date_column='A', tide_column='B', debug=False, show_errors=5, delimiter=None):
    """
    Charger les donn√©es de mar√©e depuis un fichier CSV
    
    Format attendu du CSV:
    Colonne A: Date/Heure (formats accept√©s: YYYY-MM-DD HH:MM:SS, DD/MM/YYYY HH:MM, etc.)
    Colonne B: Niveau de mar√©e en m√®tres (nombre d√©cimal)
    
    Args:
        csv_file_path: Chemin vers le fichier CSV
        date_column: Nom ou index de la colonne date (d√©faut: 'A' ou 0)
        tide_column: Nom ou index de la colonne mar√©e (d√©faut: 'B' ou 1)
        debug: Si True, affiche les premi√®res erreurs d√©tect√©es
        show_errors: Nombre d'erreurs √† afficher en mode debug
        delimiter: S√©parateur (None = d√©tection auto, ',' ou ';' ou '\t')
    
    Returns:
        Liste de dictionnaires avec 'datetime' et 'tide_level_m'
    """
    tide_data = []
    
    # Convertir les r√©f√©rences de colonnes (A, B) en indices (0, 1)
    col_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7}
    date_idx = col_map.get(date_column.upper(), 0) if isinstance(date_column, str) and len(date_column) == 1 else int(date_column)
    tide_idx = col_map.get(tide_column.upper(), 1) if isinstance(tide_column, str) and len(tide_column) == 1 else int(tide_column)
    
    print(f"\nüìÇ CHARGEMENT DES DONN√âES DE MAR√âE DEPUIS CSV")
    print(f"{'‚îÄ'*80}")
    print(f"Fichier: {csv_file_path}")
    
    if not Path(csv_file_path).exists():
        print(f"‚ùå ERREUR: Le fichier '{csv_file_path}' n'existe pas!")
        return []
    
    # D√©tection automatique du d√©limiteur
    if delimiter is None:
        with open(csv_file_path, 'r', encoding='utf-8-sig') as f:
            first_line = f.readline()
            if ';' in first_line:
                delimiter = ';'
            elif '\t' in first_line:
                delimiter = '\t'
            else:
                delimiter = ','
        print(f"S√©parateur d√©tect√©: '{delimiter}'")
    
    print(f"Colonne date: {date_column} (index {date_idx})")
    print(f"Colonne mar√©e: {tide_column} (index {tide_idx})")
    
    try:
        with open(csv_file_path, 'r', encoding='utf-8-sig') as f:
            reader = csv.reader(f, delimiter=delimiter)
            
            # D√©tecter et sauter l'en-t√™te si pr√©sent
            first_row = next(reader)
            
            # V√©rifier si c'est un en-t√™te (contient des lettres non num√©riques)
            is_header = False
            try:
                # Essayer de convertir la valeur de mar√©e
                test_val = first_row[tide_idx].replace(',', '.').strip()
                float(test_val)
            except (ValueError, IndexError):
                is_header = True
                print(f"‚ÑπÔ∏è  En-t√™te d√©tect√©: {' | '.join(first_row[:min(5, len(first_row))])}...")
            
            # Si ce n'est pas un en-t√™te, traiter la premi√®re ligne
            if not is_header:
                f.seek(0)
                reader = csv.reader(f, delimiter=delimiter)
            
            date_formats = [
                '%Y-%m-%d %H:%M:%S',
                '%Y-%m-%d %H:%M',
                '%d/%m/%Y %H:%M:%S',
                '%d/%m/%Y %H:%M',
                '%m/%d/%Y %H:%M:%S',
                '%m/%d/%Y %H:%M',
                '%Y/%m/%d %H:%M:%S',
                '%Y/%m/%d %H:%M',
                '%Y-%m-%dT%H:%M:%S',
                '%Y-%m-%dT%H:%M:%SZ',
                '%d-%m-%Y %H:%M:%S',
                '%d-%m-%Y %H:%M',
                '%Y%m%d %H:%M:%S',
                '%Y%m%d %H:%M',
                '%d.%m.%Y %H:%M:%S',
                '%d.%m.%Y %H:%M',
            ]
            
            skipped_rows = 0
            error_samples = []
            
            for row_num, row in enumerate(reader, start=2 if is_header else 1):
                if len(row) <= max(date_idx, tide_idx):
                    skipped_rows += 1
                    if debug and len(error_samples) < show_errors:
                        error_samples.append({
                            'row': row_num,
                            'reason': f'Ligne trop courte (colonnes: {len(row)})',
                            'content': str(row)[:100]
                        })
                    continue
                
                try:
                    # Extraire la date
                    date_str = row[date_idx].strip()
                    
                    if not date_str:
                        skipped_rows += 1
                        if debug and len(error_samples) < show_errors:
                            error_samples.append({
                                'row': row_num,
                                'reason': 'Date vide',
                                'content': str(row)[:100]
                            })
                        continue
                    
                    # Essayer diff√©rents formats
                    parsed_date = None
                    for fmt in date_formats:
                        try:
                            parsed_date = datetime.strptime(date_str, fmt)
                            break
                        except ValueError:
                            continue
                    
                    if parsed_date is None:
                        skipped_rows += 1
                        if debug and len(error_samples) < show_errors:
                            error_samples.append({
                                'row': row_num,
                                'reason': f'Format de date non reconnu',
                                'content': f'Date: "{date_str}"'
                            })
                        continue
                    
                    # Rendre la date "timezone-aware" (UTC) pour comparaison avec Sentinel-2
                    from datetime import timezone
                    if parsed_date.tzinfo is None:
                        parsed_date = parsed_date.replace(tzinfo=timezone.utc)
                    
                    # Extraire le niveau de mar√©e
                    tide_str = row[tide_idx].strip().replace(',', '.')
                    
                    if not tide_str:
                        skipped_rows += 1
                        if debug and len(error_samples) < show_errors:
                            error_samples.append({
                                'row': row_num,
                                'reason': 'Niveau de mar√©e vide',
                                'content': str(row)[:100]
                            })
                        continue
                    
                    tide_level = float(tide_str)
                    
                    tide_data.append({
                        'datetime': parsed_date,
                        'tide_level_m': tide_level
                    })
                    
                except (ValueError, IndexError) as e:
                    skipped_rows += 1
                    if debug and len(error_samples) < show_errors:
                        error_samples.append({
                            'row': row_num,
                            'reason': f'Erreur: {str(e)}',
                            'content': str(row)[:100]
                        })
                    continue
        
        print(f"\n‚úÖ CHARGEMENT R√âUSSI")
        print(f"   üìä {len(tide_data)} enregistrements charg√©s")
        if skipped_rows > 0:
            print(f"   ‚ö†Ô∏è  {skipped_rows} ligne(s) ignor√©e(s) (erreur de format)")
        
        # Afficher les erreurs en mode debug
        if debug and error_samples:
            print(f"\nüîç EXEMPLES D'ERREURS (premi√®res {len(error_samples)}):")
            for err in error_samples:
                print(f"\n   Ligne {err['row']}:")
                print(f"      Raison: {err['reason']}")
                print(f"      Contenu: {err['content']}")
        
        if tide_data:
            print(f"\n   üìÖ P√©riode couverte:")
            print(f"      D√©but: {tide_data[0]['datetime'].strftime('%Y-%m-%d %H:%M')}")
            print(f"      Fin:   {tide_data[-1]['datetime'].strftime('%Y-%m-%d %H:%M')}")
            print(f"   üåä Mar√©e:")
            tide_levels = [t['tide_level_m'] for t in tide_data]
            print(f"      Min: {min(tide_levels):.2f} m")
            print(f"      Max: {max(tide_levels):.2f} m")
            print(f"      Moy: {sum(tide_levels)/len(tide_levels):.2f} m")
        
        # Suggestion si beaucoup d'erreurs
        if skipped_rows > len(tide_data) * 0.5:
            print(f"\n‚ö†Ô∏è  ATTENTION: Plus de 50% des lignes ont √©t√© ignor√©es!")
            print(f"   üí° Suggestions:")
            print(f"      - Activez le mode debug: load_tide_data_from_csv(..., debug=True)")
            print(f"      - V√©rifiez le format de vos donn√©es")
            print(f"      - V√©rifiez les colonnes date_column='{date_column}' et tide_column='{tide_column}'")
        
        return tide_data
        
    except Exception as e:
        print(f"\n‚ùå ERREUR lors du chargement du CSV: {e}")
        return []


def find_closest_tide(tide_data, target_datetime, max_time_diff_minutes=60):
    """
    Trouver le niveau de mar√©e le plus proche d'un moment donn√©
    
    Args:
        tide_data: Liste des donn√©es de mar√©e (depuis load_tide_data_from_csv)
        target_datetime: Moment cible (datetime, timezone-aware)
        max_time_diff_minutes: Diff√©rence maximale acceptable en minutes
    
    Returns:
        Dict avec 'tide_level_m', 'tide_datetime', 'time_diff_minutes' ou None
    """
    if not tide_data:
        return None
    
    # S'assurer que target_datetime est timezone-aware
    from datetime import timezone
    if target_datetime.tzinfo is None:
        target_datetime = target_datetime.replace(tzinfo=timezone.utc)
    
    # Trouver l'enregistrement le plus proche
    closest = min(tide_data, key=lambda x: abs((x['datetime'] - target_datetime).total_seconds()))
    
    time_diff_seconds = abs((closest['datetime'] - target_datetime).total_seconds())
    time_diff_minutes = time_diff_seconds / 60
    
    # V√©rifier si la diff√©rence est acceptable
    if time_diff_minutes > max_time_diff_minutes:
        return None
    
    return {
        'tide_level_m': closest['tide_level_m'],
        'tide_datetime': closest['datetime'],
        'time_diff_minutes': time_diff_minutes
    }


# ============================================================================
# PARTIE 2: API COPERNICUS - IMAGES SENTINEL-2
# ============================================================================

def get_copernicus_token(username, password):
    """Obtenir un token OAuth2 pour Copernicus"""
    url = "https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token"
    
    data = {
        "grant_type": "password",
        "username": username,
        "password": password,
        "client_id": "cdse-public"
    }
    
    response = requests.post(url, data=data, timeout=30)
    response.raise_for_status()
    return response.json()["access_token"]


# [... Reste du code identique, juste modification de la fonction main ...]


# ============================================================================
# EXEMPLE D'UTILISATION AVEC CREDENTIALS S√âCURIS√âS
# ============================================================================

if __name__ == "__main__":
    # CHARGEMENT S√âCURIS√â DES CREDENTIALS
    try:
        creds = load_credentials("credentials.json")
        username = creds['copernicus']['username']
        password = creds['copernicus']['password']
        
        print(f"‚úÖ Credentials charg√©s pour: {username}")
        
    except Exception as e:
        print(f"‚ùå Impossible de charger les credentials: {e}")
        exit(1)
    
    # Vos configurations habituelles
    csv_file = "marees.csv"
    max_cloud_cover = 20
    max_tide_time_diff = 60
    time_window_hours = 1
    
    # Le reste de votre code fonctionne normalement avec username/password
    # ...