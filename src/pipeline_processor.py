#!/usr/bin/env python3
"""
Pipeline Processor - NASA Space Apps Challenge 2025
Orchestre le t√©l√©chargement, traitement et g√©n√©ration de shapefiles
"""

import os
import sys
import json
import shutil
import zipfile
from pathlib import Path
from datetime import datetime
import subprocess
import pickle
import skimage

from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload

# Scopes pour Google Drive
SCOPES = ['https://www.googleapis.com/auth/drive.readonly']


class PipelineProcessor:
    def __init__(self, base_folder_name='Sentinel-2_Iles_Madeleine'):
        self.base_folder_name = base_folder_name
        self.temp_dir = Path('temp')
        self.zips_dir = self.temp_dir / 'zips'
        self.extracts_dir = self.temp_dir / 'extracts'
        self.output_dir = Path('output/shapefiles')
        
        # Cr√©er les dossiers n√©cessaires
        self.zips_dir.mkdir(parents=True, exist_ok=True)
        self.extracts_dir.mkdir(parents=True, exist_ok=True)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.service = None
    
    def authenticate_drive(self):
        """Authentifie avec Google Drive"""
        creds = None
        
        # Token sauvegard√©
        if os.path.exists('token.pickle'):
            with open('token.pickle', 'rb') as token:
                creds = pickle.load(token)
        
        # Si pas de credentials valides
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
            else:
                flow = InstalledAppFlow.from_client_secrets_file(
                    'credentials.json', SCOPES)
                creds = flow.run_local_server(port=0)
            
            # Sauvegarder
            with open('token.pickle', 'wb') as token:
                pickle.dump(creds, token)
        
        self.service = build('drive', 'v3', credentials=creds)
        print("‚úÖ Authentification Google Drive r√©ussie")
    
    def find_base_folder(self):
        """Trouve le dossier de base sur Drive"""
        query = f"name='{self.base_folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false"
        
        results = self.service.files().list(
            q=query,
            spaces='drive',
            fields='files(id, name)'
        ).execute()
        
        files = results.get('files', [])
        
        if not files:
            print(f"‚ùå Dossier '{self.base_folder_name}' non trouv√© sur Drive")
            return None
        
        return files[0]['id']
    
    def list_year_folders(self, parent_id):
        """Liste les dossiers d'ann√©es dans le dossier de base"""
        query = f"'{parent_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false"
        
        results = self.service.files().list(
            q=query,
            spaces='drive',
            fields='files(id, name)',
            orderBy='name'
        ).execute()
        
        files = results.get('files', [])
        
        # Filtrer pour ne garder que les ann√©es (format: YYYY)
        year_folders = []
        for file in files:
            try:
                year = int(file['name'])
                if 2000 <= year <= 2100:  # Validation ann√©e
                    year_folders.append({'id': file['id'], 'name': file['name'], 'year': year})
            except ValueError:
                continue
        
        return sorted(year_folders, key=lambda x: x['year'])
    
    def list_files_in_folder(self, folder_id):
        """Liste tous les fichiers ZIP dans un dossier"""
        query = f"'{folder_id}' in parents and trashed=false"
        
        results = self.service.files().list(
            q=query,
            spaces='drive',
            fields='files(id, name, mimeType, size)',
            pageSize=100
        ).execute()
        
        files = results.get('files', [])
        
        # Filtrer les ZIP
        zip_files = [f for f in files if f['name'].endswith('.zip')]
        
        return zip_files
    
    def download_file(self, file_id, file_name, destination):
        """T√©l√©charge un fichier depuis Drive"""
        request = self.service.files().get_media(fileId=file_id)
        
        file_path = destination / file_name
        
        with open(file_path, 'wb') as f:
            downloader = MediaIoBaseDownload(f, request)
            done = False
            
            print(f"   üì• T√©l√©chargement: {file_name}")
            
            while not done:
                status, done = downloader.next_chunk()
                if status:
                    progress = int(status.progress() * 100)
                    print(f"\r      Progression: {progress}%", end='', flush=True)
            
            print()  # Nouvelle ligne
        
        return file_path
    
    def extract_zip(self, zip_path, extract_to):
        """Extrait un fichier ZIP"""
        print(f"   üì¶ Extraction: {zip_path.name}")
        
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_to)
        
        print(f"      ‚úÖ Extrait dans: {extract_to}")
    
    def find_tci_files(self, extract_dir):
        """
        Trouve les fichiers TCI dans la structure GRANULE
        
        Structure attendue:
        extract_dir/
        ‚îî‚îÄ‚îÄ PRODUCT.SAFE/
            ‚îî‚îÄ‚îÄ GRANULE/
                ‚îî‚îÄ‚îÄ L2A_TXXXXX_AXXXXXX_YYYYMMDDTHHMMSS/
                    ‚îî‚îÄ‚îÄ IMG_DATA/
                        ‚îú‚îÄ‚îÄ TCI.jp2 (si fichiers directs)
                        ‚îî‚îÄ‚îÄ R10m/ (ou R20m, R60m)
                            ‚îî‚îÄ‚îÄ TCI_10m.jp2
        """
        tci_files = []
        
        # Chercher le dossier GRANULE
        granule_dirs = list(extract_dir.rglob('GRANULE'))
        
        if not granule_dirs:
            print(f"      ‚ö†Ô∏è  Pas de dossier GRANULE trouv√©")
            return tci_files
        
        for granule_dir in granule_dirs:
            # Lister les sous-dossiers dans GRANULE
            for subdir in granule_dir.iterdir():
                if not subdir.is_dir():
                    continue
                
                img_data_dir = subdir / 'IMG_DATA'
                
                if not img_data_dir.exists():
                    continue
                
                # Cas 1: Fichiers directement dans IMG_DATA
                direct_files = list(img_data_dir.glob('*TCI*.jp2'))
                
                if direct_files:
                    tci_files.extend(direct_files)
                    print(f"      üìç TCI trouv√© (direct): {direct_files[0].name}")
                else:
                    # Cas 2: Dans des sous-dossiers de r√©solution
                    resolution_dirs = [d for d in img_data_dir.iterdir() if d.is_dir()]
                    
                    if resolution_dirs:
                        # Trier par r√©solution (R10m < R20m < R60m)
                        resolution_dirs.sort(key=lambda x: x.name)
                        
                        # Prendre le dossier de plus petite r√©solution
                        smallest_res_dir = resolution_dirs[0]
                        
                        res_tci_files = list(smallest_res_dir.glob('*TCI*.jp2'))
                        
                        if res_tci_files:
                            tci_files.extend(res_tci_files)
                            print(f"      üìç TCI trouv√© ({smallest_res_dir.name}): {res_tci_files[0].name}")
        
        return tci_files
    
    def process_pair(self, year, tci_files):
        """Traite une paire de fichiers TCI"""
        if len(tci_files) < 2:
            print(f"      ‚ö†Ô∏è  Pas assez de fichiers TCI ({len(tci_files)})")
            return None
        
        print(f"   üîß Traitement QGIS...")
        
        # Appeler traitement_qgis.py
        tci_1 = str(tci_files[0])
        tci_2 = str(tci_files[1])
        
        try:
            # Importer et ex√©cuter traitement_qgis
            sys.path.insert(0, 'src/qgis')
            import traitement_qgis
            
            # Appeler la fonction de traitement (√† adapter selon votre code)
            mosaic_b04, mosaic_b08 = traitement_qgis.process_tci_pair(tci_1, tci_2)
            
            print(f"      ‚úÖ Mosa√Øques cr√©√©es")
            print(f"         B04: {mosaic_b04}")
            print(f"         B08: {mosaic_b08}")
            
            # Appeler code_de_surface.py
            print(f"   üîß Calcul de surface...")
            
            import code_de_surface
            
            shapefile_path = code_de_surface.process_ndvi(
                band_red=mosaic_b04,
                band_nir=mosaic_b08,
                output_dir=self.output_dir,
                output_name=f"surface_{year}.shp"
            )
            
            print(f"      ‚úÖ Shapefile cr√©√©: {shapefile_path}")
            
            return shapefile_path
            
        except Exception as e:
            print(f"      ‚ùå Erreur: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def cleanup_temp(self):
        """Nettoie les fichiers temporaires"""
        print("   üóëÔ∏è  Nettoyage des fichiers temporaires...")
        
        if self.zips_dir.exists():
            shutil.rmtree(self.zips_dir)
            self.zips_dir.mkdir()
        
        if self.extracts_dir.exists():
            shutil.rmtree(self.extracts_dir)
            self.extracts_dir.mkdir()
        
        print("      ‚úÖ Nettoyage termin√©")
    
    def process_all_years(self, progress_callback=None):
        """Traite toutes les ann√©es disponibles sur Drive"""
        print("\n" + "="*80)
        print("üöÄ D√âMARRAGE DU PIPELINE DE TRAITEMENT")
        print("="*80)
        
        # Authentification
        if not self.service:
            self.authenticate_drive()
        
        # Trouver le dossier de base
        print(f"\nüìÅ Recherche du dossier '{self.base_folder_name}'...")
        base_folder_id = self.find_base_folder()
        
        if not base_folder_id:
            return []
        
        print(f"   ‚úÖ Dossier trouv√©")
        
        # Lister les ann√©es
        print(f"\nüìÖ Liste des ann√©es disponibles...")
        year_folders = self.list_year_folders(base_folder_id)
        
        if not year_folders:
            print("   ‚ö†Ô∏è  Aucun dossier d'ann√©e trouv√©")
            return []
        
        print(f"   ‚úÖ {len(year_folders)} ann√©e(s) trouv√©e(s)")
        for yf in year_folders:
            print(f"      ‚Ä¢ {yf['name']}")
        
        # Traiter chaque ann√©e
        results = []
        
        for idx, year_folder in enumerate(year_folders):
            year = year_folder['year']
            folder_id = year_folder['id']
            
            print(f"\n{'='*80}")
            print(f"üìÖ ANN√âE {year} ({idx + 1}/{len(year_folders)})")
            print(f"{'='*80}")
            
            # Callback de progression
            if progress_callback:
                progress_callback(idx + 1, len(year_folders), year)
            
            # Lister les fichiers
            print(f"\n   üìã Liste des fichiers...")
            files = self.list_files_in_folder(folder_id)
            
            if not files:
                print(f"      ‚ö†Ô∏è  Aucun fichier ZIP trouv√©")
                continue
            
            print(f"      ‚úÖ {len(files)} fichier(s) ZIP trouv√©(s)")
            
            # T√©l√©charger les fichiers
            downloaded_zips = []
            
            for file in files:
                file_path = self.download_file(
                    file['id'],
                    file['name'],
                    self.zips_dir
                )
                downloaded_zips.append(file_path)
            
            # Extraire les fichiers
            print(f"\n   üì¶ Extraction des fichiers...")
            year_extract_dir = self.extracts_dir / str(year)
            year_extract_dir.mkdir(exist_ok=True)
            
            for zip_path in downloaded_zips:
                self.extract_zip(zip_path, year_extract_dir)
            
            # Trouver les fichiers TCI
            print(f"\n   üîç Recherche des fichiers TCI...")
            tci_files = self.find_tci_files(year_extract_dir)
            
            if not tci_files:
                print(f"      ‚ö†Ô∏è  Aucun fichier TCI trouv√©")
                self.cleanup_temp()
                continue
            
            print(f"      ‚úÖ {len(tci_files)} fichier(s) TCI trouv√©(s)")
            
            # Traiter la paire
            print(f"\n   üîß Traitement de la paire...")
            shapefile_path = self.process_pair(year, tci_files)
            
            if shapefile_path:
                results.append({
                    'year': year,
                    'shapefile': str(shapefile_path),
                    'status': 'success'
                })
            else:
                results.append({
                    'year': year,
                    'shapefile': None,
                    'status': 'failed'
                })
            
            # Nettoyage
            self.cleanup_temp()
        
        # R√©sum√© final
        print(f"\n{'='*80}")
        print("üìä R√âSUM√â DU TRAITEMENT")
        print(f"{'='*80}")
        
        successful = [r for r in results if r['status'] == 'success']
        failed = [r for r in results if r['status'] == 'failed']
        
        print(f"\n   ‚úÖ R√©ussis: {len(successful)}/{len(results)}")
        print(f"   ‚ùå √âchecs: {len(failed)}/{len(results)}")
        
        if successful:
            print(f"\n   üìÅ Shapefiles g√©n√©r√©s:")
            for r in successful:
                print(f"      ‚Ä¢ {r['year']}: {Path(r['shapefile']).name}")
        
        return results


if __name__ == "__main__":
    processor = PipelineProcessor()
    results = processor.process_all_years()
    
    # Sauvegarder les r√©sultats
    results_file = Path('output/processing_results.json')
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nüíæ R√©sultats sauvegard√©s dans: {results_file}")